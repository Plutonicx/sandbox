{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "from keras_tqdm import TQDMNotebookCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"wonderland.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  144412\n",
      "Total Vocab:  47\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  144312\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Callback for loss logging per epoch\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=0, mode='auto')   \n",
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [TQDMNotebookCallback(leave_inner = True, leave_outer = True), history, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2000f6535c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, nb_epoch=20, batch_size=128, verbose=0, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = history.losses\n",
    "val_loss = history.val_losses\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('VGG-16 Loss Trend')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,nb_epoch)[0::2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2]",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "0320a18b0d4e490a8e9bcb8e95a58cd0": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "0778b46ca6f0485ca202ebac7e453f07": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "31afaadd1e004d46b50791d38fd548ea": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "366a666e493c4f88922773e57f5aeb5d": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "3926befc9a51419a89b729d546a8fd0b": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "3b5135048e074b909b306896150184fb": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "4107b6788ef449e28b9093bcc68af3e4": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "447e9bf97cf04141afdb31ae53618ce2": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "4546d53036154456b67d771f46b18fb4": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "47247ddc4a264bfb9f79137ecea0745d": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "54a2e684be9346508125bcaac0e51198": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "5504107b7e7640cf85854033c33b3602": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "68b16c1809224450bca4610f542c2473": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "76484e2f636c4cb18a9ca3008f403556": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "78aaf704bff7419ca6294d2d2621ed25": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "9637a764f7854c50a69bf60ecd1be440": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "96c510bad1c64884b6f600bc8d536b1f": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "baa25b3258844bfbae2f42f606a352ee": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "d75be7e3ce354f66a878b869db1ea8fe": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "e0dcf618de27424db7f4bad6283e103d": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "f57579960db041339688296a2d1929ec": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "f770c14b654e40709e420e3080114c77": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
